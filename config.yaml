model_path: "models/Qwen3-0.6B-Q2_K_L.gguf"
llama_path: "/../llama.cpp/llama/bin/llama-cli"
threads: 4
ctx_size: 2048
predict: 128
