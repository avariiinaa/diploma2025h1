model_path: models/Qwen3-0.6B-Q2_K_L.gguf
llama_path: /../llama.cpp/llama/bin/llama-cli
threads: 4
ctx_size: 512
predict: 64
temp: 0
topk: 40
topp: 1
pen: 1
minp: 0