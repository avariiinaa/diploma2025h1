#!/bin/bash

CONFIG_FILE="config.yaml"

MODEL_PATH=$(grep 'model_path:' $CONFIG_FILE | awk '{print $2}' | tr -d '"')
THREADS=$(grep 'threads:' $CONFIG_FILE | awk '{print $2}')
CTX_SIZE=$(grep 'ctx_size:' $CONFIG_FILE | awk '{print $2}')
PREDICT=$(grep 'predict:' $CONFIG_FILE | awk '{print $2}')

echo "ðŸ“¦ Qwen-Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½Ñ CLI (Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼)"
echo "  ðŸ§  ÐœÐ¾Ð´ÐµÐ»ÑŒ: $MODEL_PATH"
echo "  ðŸ”§ ÐŸÐ¾Ñ‚Ð¾ÐºÐ¸: $THREADS | ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: $CTX_SIZE | Ð¢Ð¾ÐºÐµÐ½Ñ‹: $PREDICT"
echo "  ðŸ’¡ ÐÐ°Ð¿ÐµÑ‡Ð°Ñ‚Ð°Ð¹ 'exit' Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ñ‹Ð¹Ñ‚Ð¸."
echo

while true; do
  read -p "ðŸ“ Ð’Ð²Ð¾Ð´> " PROMPT

  if [[ "$PROMPT" == "exit" ]]; then
    echo "ðŸ‘‹ Ð’Ñ‹Ñ…Ð¾Ð´."
    break
  fi

  ./llama.cpp/build/bin/main \
      -m "$MODEL_PATH" \
      -t "$THREADS" \
      -c "$CTX_SIZE" \
      -n "$PREDICT" \
      -p "$PROMPT"

  echo
done
